{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0Q7oDHoKUvBtfynUFNzI3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shrav-jally/ML_lab_sem5/blob/main/sem5_ml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kKoBdcTeRYz"
      },
      "outputs": [],
      "source": [
        "#tinyurl.com/ML-2025-26\n",
        "\n",
        "'''\n",
        "numpy\n",
        "pandas\n",
        "scikitlearn\n",
        "matplotlib\n",
        "tensorflow\n",
        "keras\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "creating dataframe\n",
        "inserting, deleting, modifying data\n",
        "basic and advanced dataframe ops (head, tail, shape, info, describe, groupby, join, merge, missing data handling)\n",
        "missing data handling - dropping, filling, indentifying missing values (isnull(), notnull())\n",
        "working with categorical data (data that can only take a limited number of values) - converting to categorical data, one-hot encoding, label encoding\n",
        "data visualization with pandas - line, bar, scatter, histograms\n",
        "advaced-data analysis techniques - pandas, time series analysis, statistical modelling, machine learning\n",
        "performance optimisation - vectorised operations, data types, indexing, avoid unnecessary copies\n",
        "'''"
      ],
      "metadata": {
        "id": "UlspcwvGgQfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#working with dataframes\n",
        "\n",
        "df = pd.read_csv('your_dataset.csv') #csv (comma separated vectors)\n",
        "print(df.head())\n",
        "print(df.describe()) #summary of statistics\n",
        "print(df.info())\n",
        "df.sample() #gives random 5 rows of dataframe\n",
        "df.columns\n",
        "df[['Age', 'BMI']].head() #selecting multiple columns (passing array of feature names)\n",
        "df[0:4] #0 to 4 rows of dataset (or you can use iloc(), loc() functions)\n",
        "df.rename(columns={\"Age\":\"age\"}).head() #object.method.method - pattern is called \"chain of function calls\"\n",
        "\n",
        "#handling missing values\n",
        "print(df.isnull().sum())  #check for missing values\n",
        "df_cleaned=df.dropna()  #drop rows with missing values and place it in new variable\n",
        "df_filled=df.fillna(df.mean())\n",
        "#drop() parameters - labels (list of columns to drop), axis (default=0, 0=rows, 1=columns), columns, level (if there are multiple rows in dataframe), inplace (if false return copy, otherwise do op in place and return none)\n",
        "\n",
        "df.fillna(df.mean(), inplace=True)\n",
        "print(df.duplicated().sum()) #identifies duplicate values\n",
        "df_no_duplicates = df.drop_duplicates()\n",
        "df[\"column1\"]=df[\"column1\"].astype(float)\n",
        "\n",
        "#encode categorical variables\n",
        "df_encode = pd.get_dummies(df, columns=[car_brand]) #to convert categorical data from car_brand to numerical data\n",
        "#dummy value is assigned to label name\n",
        "#this just means that the numbers the brand name is converted to it not interperted as 1 is greater than 0, but it tells the algorithm that both 1 and 0 are placveholders for categorical data"
      ],
      "metadata": {
        "id": "FJzt_9akjels"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Scikit_learn (estimator api) - pip install scikitlearn\n",
        "#uci ml repository - all types of machine learning datasets available\n",
        "#it provides various tools for - classification, regression, clustering, dimensionality reduction, feature selection\n",
        "#sklearn is used to build ml models, for data reading and manipulation and summarizing use pandas, numpy etc.\n",
        "\n",
        "import sklearn\n",
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()\n",
        "print(iris.data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZVAkw8enU2N",
        "outputId": "6c5abe3a-2758-4f39-9f1a-7e759d003660"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from re import X\n",
        "from inspect import isroutine\n",
        "'''\n",
        "components of sklearn:\n",
        "\n",
        "supervised learning algorithms: SVM, DT\n",
        "cross validation: to check accuracy of supervised models on unseen data using sklearn\n",
        "unsupervised learning algorithms: clustering, factor analysis, principal component analysis to undupervised neural networks\n",
        "various datasets: IRIS\n",
        "feature extraction: sklearn for extracting images and text features\n",
        "model selection: comparing, validating parameters and models\n",
        "'''\n",
        "\n",
        "#most common steps involved in machine learning\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Create and train the model\n",
        "clf = RandomForestClassifier(n_estimators=100)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgI5rXZCqKWE",
        "outputId": "102812bf-577f-40a9-9415-d2346083d875"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "1. **Series vs 1-D array, List, Dictionary:**\n",
        "   - **Series:** A 1-D labeled array in pandas with index labels for each element.\n",
        "   - **1-D Array:** Homogeneous, no labels (NumPy array).\n",
        "   - **List:** A Python built-in collection, ordered, but no indexing.\n",
        "   - **Dictionary:** Key-value pair mapping, unordered, no numerical operations like Series.\n",
        "\n",
        "2. **DataFrame vs 2-D array:**\n",
        "   - **DataFrame:** 2-D labeled table with heterogeneous data types (columns can have different types).\n",
        "   - **2-D Array:** Homogeneous (same data type), no labels, and lacks advanced functionality like a DataFrame.\n",
        "\n",
        "3. **DataFrames and Series:**\n",
        "   - A **DataFrame** is a collection of **Series** (each column in a DataFrame is a Series).\n",
        "\n",
        "4. **Size of (i) Series, (ii) DataFrame:**\n",
        "   - **Series Size:** Number of elements (length of the Series).\n",
        "   - **DataFrame Size:** Total elements (rows Ã— columns).\n",
        "'''\n",
        "\n",
        "\n",
        "# 5. Create the following Series and do the specified operations:\n",
        "\n",
        "# a) EngAlph with 26 alphabet elements and default indices\n",
        "import pandas as pd\n",
        "import string\n",
        "\n",
        "EngAlph = pd.Series(list(string.ascii_uppercase))\n",
        "print(EngAlph)\n",
        "\n",
        "# b) Vowels with specific index labels and all values set to zero\n",
        "Vowels = pd.Series([0]*5, index=['a', 'e', 'i', 'o', 'u'])\n",
        "print(Vowels.empty)  # Check if it is empty\n",
        "\n",
        "# c) Friends from a dictionary\n",
        "Friends = pd.Series({'John': 1, 'Alice': 2, 'Bob': 3, 'Charlie': 4, 'David': 5})\n",
        "print(Friends)\n",
        "\n",
        "# d) MTseries as an empty series\n",
        "MTseries = pd.Series()\n",
        "print(MTseries.empty)  # Check if it is empty\n",
        "\n",
        "# e) MonthDays from a numpy array\n",
        "import numpy as np\n",
        "MonthDays = pd.Series(np.array([31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]), index=np.arange(1, 13))\n",
        "print(MonthDays)\n",
        "\n",
        "# 6. Using the Series created in Question 5:\n",
        "\n",
        "# a) Set all values of Vowels to 10\n",
        "Vowels[:] = 10\n",
        "print(Vowels)\n",
        "\n",
        "# b) Divide all values of Vowels by 2\n",
        "Vowels /= 2\n",
        "print(Vowels)\n",
        "\n",
        "# c) Create another series Vowels1\n",
        "Vowels1 = pd.Series([2, 5, 6, 3, 8], index=['a', 'e', 'i', 'o', 'u'])\n",
        "print(Vowels1)\n",
        "\n",
        "# d) Add Vowels and Vowels1 and assign to Vowels3\n",
        "Vowels3 = Vowels + Vowels1\n",
        "print(Vowels3)\n",
        "\n",
        "# e) Subtract, multiply, and divide Vowels by Vowels1\n",
        "Vowels_sub = Vowels - Vowels1\n",
        "Vowels_mul = Vowels * Vowels1\n",
        "Vowels_div = Vowels / Vowels1\n",
        "print(Vowels_sub, Vowels_mul, Vowels_div)\n",
        "\n",
        "# f) Alter labels of Vowels1\n",
        "Vowels1.index = ['A', 'E', 'I', 'O', 'U']\n",
        "print(Vowels1)\n",
        "\n",
        "# 7. Using the Series created in Question 5:\n",
        "\n",
        "# a) Find dimensions, size, and values\n",
        "print(EngAlph.shape, Vowels.size, Friends.values)\n",
        "\n",
        "# b) Rename MTseries as SeriesEmpty\n",
        "SeriesEmpty = MTseries\n",
        "print(SeriesEmpty)\n",
        "\n",
        "# c) Name the index of MonthDays and Friends\n",
        "MonthDays.index.name = 'monthno'\n",
        "Friends.index.name = 'Fname'\n",
        "\n",
        "# d) Display the 3rd and 2nd value of Friends\n",
        "print(Friends.iloc[2], Friends.iloc[1])\n",
        "\n",
        "# e) Display alphabets 'e' to 'p' from EngAlph\n",
        "print(EngAlph['E':'P'])\n",
        "\n",
        "# f) Display the first 10 values of EngAlph\n",
        "print(EngAlph.head(10))\n",
        "\n",
        "# g) Display the last 10 values of EngAlph\n",
        "print(EngAlph.tail(10))\n",
        "\n",
        "# h) Display MTseries\n",
        "print(MTseries)\n",
        "\n",
        "# 8. Using the Series created in Question 5:\n",
        "\n",
        "# a) Display months 3 through 7 from MonthDays\n",
        "print(MonthDays[3:8])\n",
        "\n",
        "# b) Display MonthDays in reverse order\n",
        "print(MonthDays[::-1])\n",
        "\n",
        "# 9. Create the following DataFrame Sales:\n",
        "Sales = pd.DataFrame({\n",
        "    '2014': [100.5, 150.8, 200.9, 30000, 40000],\n",
        "    '2015': [12000, 18000, 22000, 30000, 45000],\n",
        "    '2016': [20000, 50000, 70000, 100000, 125000],\n",
        "    '2017': [50000, 60000, 70000, 80000, 90000]\n",
        "}, index=['Madhu', 'Kusum', 'Kinshuk', 'Ankit', 'Shruti'])\n",
        "print(Sales)\n",
        "\n",
        "# 10. Use the DataFrame Sales to do the following:\n",
        "\n",
        "# a) Display row labels\n",
        "print(Sales.index)\n",
        "\n",
        "# b) Display column labels\n",
        "print(Sales.columns)\n",
        "\n",
        "# c) Display data types of each column\n",
        "print(Sales.dtypes)\n",
        "\n",
        "# d) Display dimensions, shape, size, and values\n",
        "print(Sales.shape, Sales.size, Sales.values)\n",
        "\n",
        "# e) Display the last two rows\n",
        "print(Sales.tail(2))\n",
        "\n",
        "# f) Display the first two columns\n",
        "print(Sales.iloc[:, :2])\n",
        "\n",
        "# g) Create Sales2 DataFrame from dictionary\n",
        "Sales2 = pd.DataFrame({\n",
        "    '2018': [160000, 110000, 500000, 340000, 900000]\n",
        "}, index=['Madhu', 'Kusum', 'Kinshuk', 'Ankit', 'Shruti'])\n",
        "print(Sales2)\n",
        "\n",
        "# h) Check if Sales2 is empty\n",
        "print(Sales2.empty)\n",
        "\n",
        "# 11. Use the DataFrame Sales to do the following:\n",
        "\n",
        "# a) Append Sales2 to Sales\n",
        "Sales = Sales.append(Sales2)\n",
        "print(Sales)\n",
        "\n",
        "# b) Transpose the Sales DataFrame\n",
        "Sales = Sales.T\n",
        "print(Sales)\n",
        "\n",
        "# c) Display sales by all salespersons in 2017\n",
        "print(Sales['2017'])\n",
        "\n",
        "# d) Display sales by Madhu and Ankit in 2017 and 2018\n",
        "print(Sales.loc[['Madhu', 'Ankit'], ['2017', '2018']])\n",
        "\n",
        "# e) Display Shruti's sales in 2016\n",
        "print(Sales.loc['Shruti', '2016'])\n",
        "\n",
        "# f) Add data for Sumeet\n",
        "Sales.loc['Sumeet'] = [196.2, 37800, 52000, 78438, 38852]\n",
        "print(Sales)\n",
        "\n",
        "# g) Delete 2014 data from Sales\n",
        "Sales.drop('2014', axis=1, inplace=True)\n",
        "print(Sales)\n",
        "\n",
        "# h) Delete data for Kinshuk\n",
        "Sales.drop('Kinshuk', axis=0, inplace=True)\n",
        "print(Sales)\n",
        "\n",
        "# i) Change salesperson names\n",
        "Sales.rename(index={'Ankit': 'Vivaan', 'Madhu': 'Shailesh'}, inplace=True)\n",
        "print(Sales)\n",
        "\n",
        "# j) Update sales made by Shailesh in 2018\n",
        "Sales.loc['Shailesh', '2018'] = 100000\n",
        "print(Sales)\n",
        "\n",
        "# k) Write Sales DataFrame to a CSV file\n",
        "Sales.to_csv('SalesFigures.csv', header=False, index=False)\n",
        "\n",
        "# l) Read the CSV file and update row/column labels\n",
        "SalesRetrieved = pd.read_csv('SalesFigures.csv', header=None)\n",
        "SalesRetrieved.columns = Sales.columns\n",
        "SalesRetrieved.index = Sales.index\n",
        "print(SalesRetrieved)\n"
      ],
      "metadata": {
        "id": "4DlWrtN7w7N0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Install pymysql\n",
        "# pip install pymysql\n",
        "\n",
        "# 2. Pivot vs Pivot_table\n",
        "# pivot():\n",
        "# Used for reshaping data where you specify the index, columns, and values.\n",
        "# It requires unique index/column combinations. If there are duplicates, it throws an error.\n",
        "\n",
        "# pivot_table():\n",
        "# Similar to pivot(), but it can handle duplicate entries. It allows you to specify an aggregation function (e.g., sum, mean) to aggregate data when duplicates exist.\n",
        "# Syntax: pivot_table(index=..., columns=..., values=..., aggfunc='sum')\n",
        "\n",
        "# 3. SQLAlchemy\n",
        "# SQLAlchemy is a Python library that provides an Object Relational Mapping (ORM) interface for interacting with databases.\n",
        "\n",
        "# 4. Sort DataFrame by multiple columns\n",
        "import pandas as pd\n",
        "df = pd.DataFrame({'col1': [1, 2, 3], 'col2': [3, 2, 1]})\n",
        "df.sort_values(by=['col1', 'col2'], ascending=[True, False])\n",
        "\n",
        "# 5. Handling missing values\n",
        "df.fillna(value=0)  # Fill with 0\n",
        "df.dropna()         # Drop rows with missing values\n",
        "\n",
        "# 6. Median, Standard Deviation, and Variance\n",
        "import numpy as np\n",
        "data = [1, 2, 3, 4, 5]\n",
        "median = np.median(data)\n",
        "std_dev = np.std(data)\n",
        "variance = np.var(data)\n",
        "\n",
        "# 7. Mode\n",
        "mode_value = df['column'].mode()\n",
        "\n",
        "# 8. Data Aggregation\n",
        "# Example of aggregation using groupby\n",
        "df.groupby('column_name').agg({'other_column': 'mean'})\n",
        "\n",
        "# 9. GROUP BY in SQL\n",
        "# Example using pandas\n",
        "df.groupby('column_name').agg({'other_column': 'mean'})\n",
        "\n",
        "# 10. Read data from MySQL to DataFrame\n",
        "import pymysql\n",
        "conn = pymysql.connect(host='localhost', user='username', password='password', database='database_name')\n",
        "df = pd.read_sql('SELECT * FROM table_name', conn)\n",
        "conn.close()\n",
        "\n",
        "# 11. Reshaping data example\n",
        "reshaped_df = pd.melt(df, id_vars=['id'], value_vars=['col1', 'col2'])\n",
        "\n",
        "# 12. Estimation\n",
        "# Helps make informed decisions, calculate confidence intervals, and understand reliability.\n",
        "\n",
        "# 13. Product Table operations\n",
        "import pandas as pd\n",
        "# a) Create DataFrame\n",
        "data = {\n",
        "    'Item': ['TV', 'TV', 'TV', 'AC'],\n",
        "    'Company': ['LG', 'VIDEOCON', 'LG', 'SONY'],\n",
        "    'Rupees': [12000, 10000, 15000, 14000],\n",
        "    'USD': [700, 650, 800, 750]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n",
        "\n",
        "# b) Add new rows\n",
        "new_data = pd.DataFrame({\n",
        "    'Item': ['AC', 'TV'],\n",
        "    'Company': ['SAMSUNG', 'SAMSUNG'],\n",
        "    'Rupees': [16000, 12000],\n",
        "    'USD': [850, 700]\n",
        "})\n",
        "df = df.append(new_data, ignore_index=True)\n",
        "print(df)\n",
        "\n",
        "# c) Max price of LG TV\n",
        "max_price_LG = df[(df['Item'] == 'TV') & (df['Company'] == 'LG')]['Rupees'].max()\n",
        "print(max_price_LG)\n",
        "\n",
        "# d) Sum of all products\n",
        "total_sum = df['Rupees'].sum()\n",
        "print(total_sum)\n",
        "\n",
        "# e) Median USD of Sony products\n",
        "median_usd_sony = df[df['Company'] == 'SONY']['USD'].median()\n",
        "print(median_usd_sony)\n",
        "\n",
        "# f) Sort data by Rupees\n",
        "df_sorted = df.sort_values(by='Rupees')\n",
        "print(df_sorted)\n",
        "\n",
        "# g) Transfer DataFrame to MySQL\n",
        "conn = pymysql.connect(host='localhost', user='username', password='password', database='database_name')\n",
        "df.to_sql('product_table', conn, if_exists='replace', index=False)\n",
        "conn.close()\n",
        "\n",
        "# 14. Student dataset operations\n",
        "# a) Create DataFrame\n",
        "data = {\n",
        "    'Name': ['John', 'Alice', 'Bob', 'Charlie'],\n",
        "    'Degree': ['BCA', 'MBA', 'BCA', 'MBA'],\n",
        "    'Marks': [76, 89, 45, 88]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# b) Degree and max marks in each stream\n",
        "df.groupby('Degree')['Marks'].max()\n",
        "\n",
        "# c) Fill NaN with 76\n",
        "df.fillna(76, inplace=True)\n",
        "\n",
        "# d) Set index to Name\n",
        "df.set_index('Name', inplace=True)\n",
        "\n",
        "# e) Name and degree-wise average marks of each student\n",
        "df.groupby(['Degree']).agg({'Marks': 'mean'})\n",
        "\n",
        "# f) Count number of students in MBA\n",
        "mba_count = df[df['Degree'] == 'MBA'].shape[0]\n",
        "print(mba_count)\n",
        "\n",
        "# g) Mode of marks in BCA\n",
        "bca_mode = df[df['Degree'] == 'BCA']['Marks'].mode()\n",
        "print(bca_mode)\n",
        "\n",
        "# UCI Dataset (auto-mpg) operations\n",
        "# 1) Load the dataset\n",
        "autodf = pd.read_csv('auto-mpg.data', delim_whitespace=True, header=None)\n",
        "\n",
        "# 2) Describe the DataFrame\n",
        "print(autodf.describe())\n",
        "\n",
        "# 3) Display first 10 rows\n",
        "print(autodf.head(10))\n",
        "\n",
        "# 4) Handle missing values\n",
        "autodf.fillna(method='ffill', inplace=True)\n",
        "autodf.dropna(inplace=True)\n",
        "\n",
        "# 5) Car with max mileage\n",
        "max_mileage_car = autodf.loc[autodf[0].idxmax()]\n",
        "print(max_mileage_car)\n",
        "\n",
        "# 6) Average displacement based on cylinders\n",
        "avg_displacement = autodf.groupby(1)[3].mean()\n",
        "print(avg_displacement)\n",
        "\n",
        "# 7) Average number of cylinders\n",
        "avg_cylinders = autodf[1].mean()\n",
        "print(avg_cylinders)\n"
      ],
      "metadata": {
        "id": "Mdho8ROkw6f0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}